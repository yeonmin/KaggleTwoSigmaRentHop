{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "from itertools import product\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from subprocess import check_output\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted Average Stacking\n",
    "* 여러가지 방법으로 학습한 결과를 마지막에 결과가 서로 상관관계가 적거나 혹은 결과가 좋은 Model 여러개를 사용하여 결과를 합침<br>\n",
    "* 아래 사이트를 참고하였고 간단하게는 결과를 합친 뒤 평균을 내는 것 같아 이 코드를 작성함\n",
    "<br>https://mlwave.com/kaggle-ensembling-guide/\n",
    "* 이 코드에서 각 결과에 가중치를 주는 방법은 결과 파일을 폴더 내에 몇 번 Copy하냐에 따라서 가중치의 계수 결정됨<br>\n",
    "**Example**<br>\n",
    "A,B,C,D 결과가 있을 경우 A에 가중치 3을 주고 싶을 때 A를 Copy하여 A', A''를 만들어주면 (A+A'+A''+B+C+D)/6 으로 계산됨\n",
    "\n",
    "**사용 방법**<br>\n",
    ">1. StackNet 혹은 다른 방법으로 나온 결과 파일을 한 폴더에 모아 놓는다.\n",
    ">2. stacking_path에 폴더 Path를 입력\n",
    ">3. 아래 순서로 실행하고 마지막에 결과파일의 이름을 변경하여 제출한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stacking_path = 'ensemble/submit/E9/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['low','medium','high','listing_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E10_folder_ensemble_20170426_1.csv\n",
      "empty\n",
      "E1_folder_ensemble_20170423_5.csv\n",
      "in\n",
      "E2_folder_ensemble_20170424_2.csv\n",
      "in\n",
      "E3_folder_ensemble_20170425_5.csv\n",
      "in\n",
      "E4_folder_ensemble_20170425_2.csv\n",
      "in\n",
      "E5_folder_ensemble_20170425_3.csv\n",
      "in\n",
      "E7_folder_ensemble_20170426_1.csv\n",
      "in\n",
      "E8_folder_ensemble_20170426_3 - 복사본 (2).csv\n",
      "in\n",
      "E8_folder_ensemble_20170426_3 - 복사본.csv\n",
      "in\n",
      "E8_folder_ensemble_20170426_3.csv\n",
      "in\n"
     ]
    }
   ],
   "source": [
    "file_list = []\n",
    "file_path_list=[]\n",
    "try:\n",
    "    for file in listdir(stacking_path):\n",
    "        \n",
    "        if file.find('.csv')==-1:\n",
    "            continue\n",
    "            \n",
    "        print(file)    \n",
    "        file_list.append(file)\n",
    "        file_path = join(stacking_path,file)\n",
    "        file_path_list.append(file_path)\n",
    "        temp = pd.read_csv(file_path)\n",
    "        if df.empty == True:\n",
    "            print(\"empty\")\n",
    "            df = df.append(temp)\n",
    "        else:\n",
    "            print(\"in\")\n",
    "            df = df.merge(temp,on='listing_id')\n",
    "except:\n",
    "    print(\"exception\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if 'low' in df.columns:\n",
    "    df['low_result'] = df['low_x'].mean(axis=1) + df['low_y'].mean(axis=1) + df['low']\n",
    "    df['medium_result'] = df['medium_x'].mean(axis=1) + df['medium_y'].mean(axis=1) + df['medium']\n",
    "    df['high_result'] = df['high_x'].mean(axis=1) + df['high_y'].mean(axis=1) + df['high']\n",
    "\n",
    "    df['low_result'] = df['low_result']/3\n",
    "    df['medium_result'] = df['medium_result']/3\n",
    "    df['high_result'] = df['high_result']/3\n",
    "    \n",
    "    del df['low_x'],df['low_y'],df['medium_x'],df['medium_y'],df['high_x'],df['high_y'],df['high'],df['medium'],df['low']\n",
    "    \n",
    "else:\n",
    "    df['low_result'] = df['low_x'].mean(axis=1) + df['low_y'].mean(axis=1) \n",
    "    df['medium_result'] = df['medium_x'].mean(axis=1) + df['medium_y'].mean(axis=1) \n",
    "    df['high_result'] = df['high_x'].mean(axis=1) + df['high_y'].mean(axis=1)\n",
    "\n",
    "    df['low_result'] = df['low_result']/2\n",
    "    df['medium_result'] = df['medium_result']/2\n",
    "    df['high_result'] = df['high_result']/2\n",
    "    \n",
    "    del df['low_x'],df['low_y'],df['medium_x'],df['medium_y'],df['high_x'],df['high_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.rename(columns={'low_result':'low','medium_result':'medium','high_result':'high'},inplace=True)\n",
    "df['listing_id'] = df['listing_id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_csv(join(stacking_path,'E9_folder_ensemble_20170426_1.csv'),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Calculate Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stacking_base_file = 'E8_folder_ensemble_20170426_3.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stacking_path = 'ensemble/submit/E9/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_correlation(base_df,target):\n",
    "    source = base_df.copy()\n",
    "    source = source.merge(target,on='listing_id')\n",
    "    corr_df = source.corr()\n",
    "    low_corr = corr_df.ix['low_x']['low_y']\n",
    "    medium_corr = corr_df.ix['medium_x']['medium_y']\n",
    "    high_corr = corr_df.ix['high_x']['high_y']\n",
    "    \n",
    "    del corr_df,source\n",
    "    return low_corr,medium_corr,high_corr, (low_corr+medium_corr+high_corr)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def is_same_listing_id(source,target):\n",
    "    return 1 if np.sum(source['listing_id'] - target['listing_id']) == 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E10_folder_ensemble_20170426_1.csv\n",
      "E10_folder_ensemble_20170426_1.csv 0.997999462643\n",
      "\n",
      "E1_folder_ensemble_20170423_5.csv\n",
      "E1_folder_ensemble_20170423_5.csv 0.994741764178\n",
      "\n",
      "E2_folder_ensemble_20170424_2.csv\n",
      "E2_folder_ensemble_20170424_2.csv 0.994714336959\n",
      "\n",
      "E3_folder_ensemble_20170425_5.csv\n",
      "E3_folder_ensemble_20170425_5.csv 0.994911320929\n",
      "\n",
      "E4_folder_ensemble_20170425_2.csv\n",
      "E4_folder_ensemble_20170425_2.csv 0.996427804291\n",
      "\n",
      "E5_folder_ensemble_20170425_3.csv\n",
      "E5_folder_ensemble_20170425_3.csv 0.996272126743\n",
      "\n",
      "E7_folder_ensemble_20170426_1.csv\n",
      "E7_folder_ensemble_20170426_1.csv 0.999937168391\n",
      "\n",
      "E8_folder_ensemble_20170426_3 - 복사본 (2).csv\n",
      "E8_folder_ensemble_20170426_3 - 복사본 (2).csv 1.0\n",
      "\n",
      "E8_folder_ensemble_20170426_3 - 복사본.csv\n",
      "E8_folder_ensemble_20170426_3 - 복사본.csv 1.0\n",
      "\n",
      "E8_folder_ensemble_20170426_3.csv\n",
      "E8_folder_ensemble_20170426_3.csv 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_list = []\n",
    "file_path_list=[]\n",
    "base_df = pd.read_csv(join(stacking_path,stacking_base_file))\n",
    "corr_dict = dict()\n",
    "try:\n",
    "    for file in listdir(stacking_path):\n",
    "        \n",
    "        if file.find('.csv')==-1:\n",
    "            continue\n",
    "            \n",
    "        print(file)    \n",
    "        file_list.append(file)\n",
    "        file_path = join(stacking_path,file)\n",
    "        file_path_list.append(file_path)\n",
    "        #print(file_path)\n",
    "        temp = pd.read_csv(file_path)\n",
    "\n",
    "        if is_same_listing_id(base_df,temp) == 0:    \n",
    "            continue\n",
    "\n",
    "        l,m,h,c = calculate_correlation(base_df,temp)\n",
    "        corr_dict[file]=c\n",
    "        print(file,c)\n",
    "        print(\"\")\n",
    "except:\n",
    "    print(\"exception\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pred_ex64_nineth.csv',\n",
       " 'pred_ex60_ensemble.csv',\n",
       " 'top_corr_ensemble_base_before_top.csv',\n",
       " 'top5_ensemble.csv',\n",
       " 'top5_ensemble_base_before_top.csv',\n",
       " 'top5_ensemble_20170418.csv',\n",
       " 'just_voting1.csv',\n",
       " 'top5_2_result_with_nineth.csv',\n",
       " 'top5_2_result_without_nineth.csv',\n",
       " 'top5_2_result - 복사본.csv',\n",
       " 'top5_2_result.csv',\n",
       " 'top5_2_result - 복사본 (2).csv']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(corr_dict,key=corr_dict.get)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
